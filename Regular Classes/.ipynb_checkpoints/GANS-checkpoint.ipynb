{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a0b71d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets.mnist import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8e44ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(input_shape = (28, 28, 1)):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(20, (5, 5), padding = 'same', input_shape = input_shape))\n",
    "    model.add(keras.layers.LeakyReLU(alpha = 0.1))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Conv2D(20, (5, 5), padding = 'same', input_shape = input_shape))    # Change input size to input shape \n",
    "    model.add(keras.layers.LeakyReLU(alpha = 0.1))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Conv2D(20, (5, 5), padding = 'same', input_shape = input_shape))\n",
    "    model.add(keras.layers.LeakyReLU(alpha = 0.1))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Conv2D(20, (5, 5), padding = 'same', input_shape = input_shape))\n",
    "    model.add(keras.layers.LeakyReLU(alpha = 0.1))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5b3ee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(latent_dim):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(150, input_shape = (latent_dim,)))\n",
    "    model.add(keras.layers.LeakyReLU(alpha = 0.1))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(300, input_shape = (latent_dim,)))\n",
    "    model.add(keras.layers.LeakyReLU(alpha = 0.1))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(450, input_shape = (latent_dim,)))\n",
    "    model.add(keras.layers.LeakyReLU(alpha = 0.1))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(600, input_shape = (latent_dim,)))    #convert latent_dim to an array (latent_dim,)\n",
    "    model.add(keras.layers.LeakyReLU(alpha = 0.1))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(784, input_shape = (latent_dim,)))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Reshape((28, 28, 1)))\n",
    "    # model.add(keras.activations.sigmoid())\n",
    "    model.add(keras.layers.Activation('sigmoid'))  #change this here , use .layers as well, above gives errors \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb970fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gans(g_model, d_model):\n",
    "    d_model.trainable = False\n",
    "    model = keras.Sequential()\n",
    "    model.add(g_model)\n",
    "    model.add(d_model)\n",
    "    \n",
    "    model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8194be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_samples():\n",
    "    (train_x,_),(_,_)=load_data()\n",
    "    train_x=np.expand_dims(train_x,axis=-1)\n",
    "    train_x=train_x.astype('float32')\n",
    "    train_x=train_x/255\n",
    "\n",
    "    return train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeff7a3c-9c27-46f0-99b1-44f2014ed4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset,n_samples):\n",
    "    ids=np.random.randint(0,dataset.shape[0],n_samples)\n",
    "    dataset=dataset[ids]\n",
    "    y=np.ones((n_samples,1))\n",
    "    return dataset,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "927964d0-5322-4e34-b993-b754a31646f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_noise(latent_dim,n_samples):\n",
    "    noise=np.random.randn(latent_dim*n_samples)\n",
    "    noise=noise.reshape(n_samples,latent_dim)\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af9dd6e9-02f6-4dda-8c3d-67863fb388c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(g_model,latent_dim,n_samples):\n",
    "    noise=generate_latent_noise(latent_dim,n_samples)\n",
    "    fake_data=g_model.predict(noise)\n",
    "    y=np.zeros((n_samples,1))\n",
    "    return fake_data, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1a6de31-a6f5-4c34-9518-92f9ea7d509b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(g_model,d_model,dataset,latent_dim,epoch,n_samples=30):\n",
    "    x_real,y_real=generate_real_samples(dataset,n_samples)\n",
    "    loss_real,acc_real=d_model.evaluate(x_real,y_real)       #spelling error for evaluate\n",
    "    x_fake,y_fake=generate_fake_samples(g_model,latent_dim,n_samples)\n",
    "    loss_fake,acc_fake=d_model.evaluate(x_fake,y_fake)\n",
    "    print(f'Accuracy real:{acc_real*100}%, Accuracy fake:{acc_fake*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c294ea2f-6ba1-463e-819a-f2f8a69d2674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_model,d_model,define_gan,dataset,latent_dim,n_epoch=10,n_batch=500):\n",
    "    batches_per_epoch=int(dataset.shape[0]/n_batch)\n",
    "    n_samples=250\n",
    "    for i in range(n_epoch):\n",
    "        for j in range(batches_per_epoch):\n",
    "            x_real,y_real=generate_real_samples(dataset,n_samples)\n",
    "            x_fake,y_fake=generate_fake_samples(g_model,latent_dim,n_samples)\n",
    "\n",
    "            d_loss_real,_=d_model.train_on_batch(x_real,y_real)\n",
    "            d_loss_fake,_=d_model.train_on_batch(x_fake,y_fake)\n",
    "\n",
    "            d_loss=d_loss_fake+d_loss_real\n",
    "\n",
    "            noise=generate_latent_noise(latent_dim,n_samples)\n",
    "\n",
    "            y_gan=np.ones((n_samples,1))   # replace -1 with 1\n",
    "            g_loss,_=define_gan.train_on_batch(noise,y_gan)\n",
    "            print(f'on epoch:{i+1}, Disc Loss: {d_loss}, Gen Loss: {g_loss}')\n",
    "\n",
    "            if i % 10 ==0:\n",
    "                summary(g_model,d_model,dataset,latent_dim,i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c80150c6-9f04-43b8-8035-62799a5b5e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step\n",
      "on epoch:1, Disc Loss: 1.4919045567512512, Gen Loss: 0.6653316020965576\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.6637 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6993 - accuracy: 0.0000e+00\n",
      "Accuracy real:100.0%, Accuracy fake:0.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 1.3528393507003784, Gen Loss: 0.6810035109519958\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6567 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6935 - accuracy: 0.4000\n",
      "Accuracy real:100.0%, Accuracy fake:40.00000059604645%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 1.3312363028526306, Gen Loss: 0.6851128339767456\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6187 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6881 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 1.2781133651733398, Gen Loss: 0.6701441407203674\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4981 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6896 - accuracy: 0.6333\n",
      "Accuracy real:100.0%, Accuracy fake:63.333332538604736%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 1.201671153306961, Gen Loss: 0.5917313098907471\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2925 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7440 - accuracy: 0.0333\n",
      "Accuracy real:100.0%, Accuracy fake:3.333333507180214%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 1.182855099439621, Gen Loss: 0.5483255982398987\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1794 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8373 - accuracy: 0.0000e+00\n",
      "Accuracy real:100.0%, Accuracy fake:0.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 1.079872116446495, Gen Loss: 0.7091478705406189\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1822 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7013 - accuracy: 0.4000\n",
      "Accuracy real:100.0%, Accuracy fake:40.00000059604645%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.8655079901218414, Gen Loss: 0.9538119435310364\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2651 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5273 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.6965396553277969, Gen Loss: 1.272574543952942\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2655 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3741 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.5153762102127075, Gen Loss: 1.8376892805099487\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1530 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2166 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.29593074321746826, Gen Loss: 2.766623020172119\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0510 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0971 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.09753168746829033, Gen Loss: 4.228776454925537\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0350 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.02936320286244154, Gen Loss: 6.105124473571777\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.0073555182898417115, Gen Loss: 8.459128379821777\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.7432e-04 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.0017730129475239664, Gen Loss: 11.029438018798828\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.2947e-04 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3231e-04 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.00035824345104629174, Gen Loss: 13.488962173461914\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1826e-06 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.7583e-05 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.0002327364927623421, Gen Loss: 16.00659942626953\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.2371e-05 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.0002804883406497538, Gen Loss: 18.228105545043945\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.8318e-10 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.4453e-05 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.00032799269320094027, Gen Loss: 20.114896774291992\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.5431e-06 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.4193e-06 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 4.726886169237332e-05, Gen Loss: 21.69831085205078\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 8.2286e-07 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6.4245e-06 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 3.143222508583676e-05, Gen Loss: 23.149141311645508\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6722e-06 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7113e-06 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 3.0151169547742995e-05, Gen Loss: 24.309892654418945\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.3986e-08 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.9420e-06 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 3.6702314616832155e-05, Gen Loss: 25.504478454589844\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.1791e-08 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.5790e-06 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.00015679053285566624, Gen Loss: 26.318166732788086\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5265e-08 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.8274e-06 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.00031249875752337175, Gen Loss: 27.083545684814453\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5754e-09 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 9.6146e-06 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.0005587546766037121, Gen Loss: 27.899948120117188\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.7441e-14 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.5436e-06 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.00014889043720245354, Gen Loss: 28.63886833190918\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.7171e-11 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2260e-06 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 7.729613298579352e-05, Gen Loss: 29.467031478881836\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.3116e-10 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.0303e-06 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.00027065282814930924, Gen Loss: 30.304094314575195\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.1256e-04 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0808e-06 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.00017182935698656365, Gen Loss: 30.764219284057617\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.5970e-10 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1058e-06 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.0009672135529399384, Gen Loss: 30.822614669799805\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.4440e-08 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3894e-06 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.019595762772951275, Gen Loss: 28.559768676757812\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.4861e-10 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9520e-04 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.1298280699411407, Gen Loss: 36.21502685546875\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.7522e-10 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.3388e-10 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.06483113020667275, Gen Loss: 49.14626693725586\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7499 - accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.5708e-18 - accuracy: 1.0000\n",
      "Accuracy real:80.0000011920929%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 2.0407531261449843, Gen Loss: 33.65850830078125\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 9.7644e-09 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.8785e-10 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.01203883835387387, Gen Loss: 23.510587692260742\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.9135e-13 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3594e-04 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 1.9309781794518528, Gen Loss: 25.939727783203125\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5827e-15 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.4938e-07 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 1.4658019849983495e-10, Gen Loss: 37.25223922729492\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1236 - accuracy: 0.9667\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.8649e-14 - accuracy: 1.0000\n",
      "Accuracy real:96.66666388511658%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.12124410271644605, Gen Loss: 46.44630432128906\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5701 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6702e-19 - accuracy: 1.0000\n",
      "Accuracy real:66.66666865348816%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 2.6582529544830322, Gen Loss: 44.4478759765625\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.7540 - accuracy: 0.7667\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.7902e-18 - accuracy: 1.0000\n",
      "Accuracy real:76.66666507720947%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 1.8447924852371218, Gen Loss: 36.11814880371094\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5830 - accuracy: 0.8667\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.3878e-15 - accuracy: 1.0000\n",
      "Accuracy real:86.66666746139526%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.45208567380916004, Gen Loss: 28.651086807250977\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 8.3274e-04 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.8766e-12 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.007258121887239, Gen Loss: 23.36353874206543\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4792e-12 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2330e-10 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 1.3392044790450086e-05, Gen Loss: 19.59756851196289\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5944e-16 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0415e-08 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 4.9835531229502905e-08, Gen Loss: 16.767906188964844\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.5746e-14 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.5276e-07 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 6.240019466351946e-07, Gen Loss: 14.782096862792969\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.9456e-17 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 9.9258e-07 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 3.081740455692359e-06, Gen Loss: 13.280038833618164\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1434e-23 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.9422e-06 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 1.0633745660018917e-05, Gen Loss: 12.117387771606445\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.2519e-21 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3029e-05 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 3.7191592127801655e-05, Gen Loss: 11.245658874511719\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.3970e-28 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.6354e-05 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.0001424921938451007, Gen Loss: 10.475383758544922\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 7.4976e-28 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.2941e-04 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.0007901971112005413, Gen Loss: 9.913863182067871\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6382e-28 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.9272e-04 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.0018090226221829653, Gen Loss: 9.38390064239502\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0982e-35 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 9.7888e-04 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.0036860264372080564, Gen Loss: 8.987788200378418\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2491e-30 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.01362176239490509, Gen Loss: 8.662457466125488\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.3894e-32 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0702 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.2783619463443756, Gen Loss: 8.993721008300781\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2321e-24 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0258 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.020044131204485893, Gen Loss: 9.749147415161133\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.2037e-24 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.0028927302919328213, Gen Loss: 10.368199348449707\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0749e-25 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.3073e-04 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.0007404701318591833, Gen Loss: 10.835712432861328\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.9401e-24 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.5532e-04 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.0003177585895194901, Gen Loss: 11.11523151397705\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.9317e-22 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1068e-04 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.00014380466018339572, Gen Loss: 11.348226547241211\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.9055e-13 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.0391e-04 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.001062407041905487, Gen Loss: 11.321734428405762\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.2161e-18 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.029333850345287793, Gen Loss: 11.241926193237305\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.6011e-18 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0965 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.4365199804319215, Gen Loss: 11.9177885055542\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.6227e-13 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1351 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.03662393987831881, Gen Loss: 13.143600463867188\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8670e-09 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.0011510241356518236, Gen Loss: 14.401785850524902\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0499 - accuracy: 0.9667\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.9766e-04 - accuracy: 1.0000\n",
      "Accuracy real:96.66666388511658%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.027358321036444977, Gen Loss: 15.245739936828613\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3782 - accuracy: 0.9333\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Accuracy real:93.33333373069763%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.17894775932654738, Gen Loss: 15.35981559753418\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2133 - accuracy: 0.9333\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1305 - accuracy: 1.0000\n",
      "Accuracy real:93.33333373069763%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.4318040609359741, Gen Loss: 15.381792068481445\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1549 - accuracy: 0.9333\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5253 - accuracy: 1.0000\n",
      "Accuracy real:93.33333373069763%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.7048366367816925, Gen Loss: 15.19469165802002\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8420 - accuracy: 0.7333\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.8491 - accuracy: 0.0000e+00\n",
      "Accuracy real:73.33333492279053%, Accuracy fake:0.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 7.792497158050537, Gen Loss: 15.323315620422363\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.0550 - accuracy: 0.0667\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Accuracy real:6.666667014360428%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 5.0780406958656386, Gen Loss: 12.855904579162598\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3000 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.3019e-04 - accuracy: 1.0000\n",
      "Accuracy real:0.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 4.942248837091029, Gen Loss: 8.531586647033691\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8106 - accuracy: 0.5667\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Accuracy real:56.66666626930237%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.9044976383447647, Gen Loss: 5.16170597076416\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0960 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.37581950705498457, Gen Loss: 3.248183488845825\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.1573e-04 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.7787 - accuracy: 0.0000e+00\n",
      "Accuracy real:100.0%, Accuracy fake:0.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 2.2932771924242843, Gen Loss: 2.39748215675354\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3812 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.20977739058434963, Gen Loss: 2.070584297180176\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0270 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1280 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.1647871434688568, Gen Loss: 1.8721749782562256\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3143 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1471 - accuracy: 1.0000\n",
      "Accuracy real:83.33333134651184%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.44447365403175354, Gen Loss: 1.7495087385177612\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3469 - accuracy: 0.8333\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1176 - accuracy: 1.0000\n",
      "Accuracy real:83.33333134651184%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.5916403979063034, Gen Loss: 1.6864140033721924\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5875 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1289 - accuracy: 1.0000\n",
      "Accuracy real:66.66666865348816%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.5270191952586174, Gen Loss: 1.6501023769378662\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5311 - accuracy: 0.7667\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1753 - accuracy: 1.0000\n",
      "Accuracy real:76.66666507720947%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.4937632232904434, Gen Loss: 1.5831379890441895\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2052 - accuracy: 0.9333\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2056 - accuracy: 1.0000\n",
      "Accuracy real:93.33333373069763%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.33473794162273407, Gen Loss: 1.5913113355636597\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2389 - accuracy: 0.8667\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3730 - accuracy: 1.0000\n",
      "Accuracy real:86.66666746139526%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.43208731710910797, Gen Loss: 1.7303258180618286\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0720 - accuracy: 0.9667\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5215 - accuracy: 0.9667\n",
      "Accuracy real:96.66666388511658%, Accuracy fake:96.66666388511658%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.3563595563173294, Gen Loss: 2.1111631393432617\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0619 - accuracy: 0.9667\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6569 - accuracy: 0.9333\n",
      "Accuracy real:96.66666388511658%, Accuracy fake:93.33333373069763%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.3385908007621765, Gen Loss: 3.0676558017730713\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1277 - accuracy: 0.9333\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2380 - accuracy: 1.0000\n",
      "Accuracy real:93.33333373069763%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.19434259831905365, Gen Loss: 4.415455341339111\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1480 - accuracy: 0.9333\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0298 - accuracy: 1.0000\n",
      "Accuracy real:93.33333373069763%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.2138655250892043, Gen Loss: 5.6369309425354\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2170 - accuracy: 0.8667\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Accuracy real:86.66666746139526%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.2289547980763018, Gen Loss: 6.180301189422607\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0310 - accuracy: 0.9667\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Accuracy real:96.66666388511658%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.04202257236465812, Gen Loss: 6.150032997131348\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.7709e-04 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0302 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.03323359182104468, Gen Loss: 5.799507141113281\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.0707e-05 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1468 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.12198435366735794, Gen Loss: 6.423886775970459\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3378e-05 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1086 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.0530763667775318, Gen Loss: 8.588831901550293\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.0231e-06 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0133 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.0046183237645891495, Gen Loss: 11.296667098999023\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.9907e-06 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.6520e-04 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.0003719913656823337, Gen Loss: 13.900096893310547\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0567e-05 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.2169e-05 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.0001187223824672401, Gen Loss: 16.0816707611084\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.9171e-07 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.3640e-06 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.0012910729592476855, Gen Loss: 17.837942123413086\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.8932e-06 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9269e-06 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 7.539681371326878e-05, Gen Loss: 19.389312744140625\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.8017e-07 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.007036627118623073, Gen Loss: 20.57346534729004\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.2480e-04 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.4252e-07 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.018195667252740577, Gen Loss: 21.240375518798828\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.6858e-04 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.7092e-07 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.0035867586150004627, Gen Loss: 21.5212459564209\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.1401e-04 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4944e-07 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.0002950356611677307, Gen Loss: 21.72810173034668\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6083e-07 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.0036486644922035794, Gen Loss: 21.639089584350586\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9205e-04 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.5911e-07 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.009005967637222057, Gen Loss: 21.60768699645996\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.4871e-04 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.0583e-07 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.006804896885569178, Gen Loss: 20.943849563598633\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.8643e-06 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.6006e-06 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.004298669336094463, Gen Loss: 20.35091781616211\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.7053e-05 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.4678e-06 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.00020499576930887997, Gen Loss: 19.741092681884766\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4650e-05 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.2027e-05 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.0003604661178542301, Gen Loss: 19.190404891967773\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6570e-06 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2152e-04 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.000994234040263109, Gen Loss: 18.505062103271484\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.6783e-06 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.9663e-04 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.003988017730080173, Gen Loss: 17.786293029785156\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.8247e-04 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.012697870915872045, Gen Loss: 17.395416259765625\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2578e-06 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.01655609262888902, Gen Loss: 17.602481842041016\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3406e-04 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.013424343429505825, Gen Loss: 18.00035858154297\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0300e-05 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.8820e-04 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.0014619386638514698, Gen Loss: 17.917362213134766\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 8.6124e-05 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2487e-04 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.0009328042506240308, Gen Loss: 18.322673797607422\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.4739e-05 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.7308e-05 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.0014654978513135575, Gen Loss: 18.531274795532227\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2693e-05 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2653e-04 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.0020259789016563445, Gen Loss: 18.25461769104004\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1810e-04 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.7684e-04 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.006099320453358814, Gen Loss: 17.82206916809082\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5457e-05 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.008252290659584105, Gen Loss: 17.699600219726562\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5069e-07 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:1, Disc Loss: 0.016103163245134056, Gen Loss: 17.481674194335938\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3327e-04 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0215 - accuracy: 1.0000\n",
      "Accuracy real:100.0%, Accuracy fake:100.0%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:1, Disc Loss: 0.013190471567213535, Gen Loss: 17.45835304260254\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1925e-05 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0767 - accuracy: 0.9667\n",
      "Accuracy real:100.0%, Accuracy fake:96.66666388511658%\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.026137186549021862, Gen Loss: 17.81804656982422\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.017208045574079733, Gen Loss: 18.471168518066406\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.004185492522083223, Gen Loss: 19.20008087158203\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.005877841234905645, Gen Loss: 19.882843017578125\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.027198002208024263, Gen Loss: 20.522363662719727\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.08007919602096081, Gen Loss: 21.048852920532227\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.2089494802057743, Gen Loss: 21.879955291748047\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.10595915094017982, Gen Loss: 22.167112350463867\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.09567891620099545, Gen Loss: 22.564537048339844\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.13587410282343626, Gen Loss: 21.600528717041016\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.08166804141364992, Gen Loss: 19.950796127319336\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.00795810273848474, Gen Loss: 18.40489959716797\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.013134495413396508, Gen Loss: 16.972768783569336\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0006182516517583281, Gen Loss: 16.013153076171875\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0031087576353456825, Gen Loss: 15.047738075256348\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0005583670731539314, Gen Loss: 14.274776458740234\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0012226928079144272, Gen Loss: 13.857932090759277\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0048454291559210105, Gen Loss: 13.533929824829102\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.0031677862425567582, Gen Loss: 13.190546035766602\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.02190231864781822, Gen Loss: 13.18703842163086\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.023176120736934536, Gen Loss: 13.251785278320312\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.03160121581640851, Gen Loss: 13.660452842712402\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.008590190686845744, Gen Loss: 14.160873413085938\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0025461507320869714, Gen Loss: 14.532377243041992\n",
      "8/8 [==============================] - 0s 4ms/step\n",
      "on epoch:2, Disc Loss: 0.0009063042743946426, Gen Loss: 15.000393867492676\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.009204797621350735, Gen Loss: 15.301963806152344\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.0018753579934127629, Gen Loss: 15.317962646484375\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.000785163720138371, Gen Loss: 15.528189659118652\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.0014124381123110652, Gen Loss: 15.664653778076172\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.0021340540843084455, Gen Loss: 15.668713569641113\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.0011923178099095821, Gen Loss: 15.702808380126953\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.0012475016992539167, Gen Loss: 15.743063926696777\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0022305413149297237, Gen Loss: 15.703694343566895\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.0030926233157515526, Gen Loss: 15.646587371826172\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.002121901256032288, Gen Loss: 15.527066230773926\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0015002418658696115, Gen Loss: 15.637388229370117\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.002394728478975594, Gen Loss: 15.62370491027832\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.0021821820409968495, Gen Loss: 15.648621559143066\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.003833636932540685, Gen Loss: 15.589065551757812\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.001430039555998519, Gen Loss: 15.624412536621094\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0011410046718083322, Gen Loss: 15.822051048278809\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.001424084068275988, Gen Loss: 15.706007957458496\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0015642521320842206, Gen Loss: 15.905159950256348\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0015372667112387717, Gen Loss: 15.880910873413086\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0008312161808134988, Gen Loss: 15.97836685180664\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.001856227550888434, Gen Loss: 15.924660682678223\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.003902136697433889, Gen Loss: 16.03360939025879\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0016006984806153923, Gen Loss: 16.08270263671875\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.001802894490538165, Gen Loss: 16.14300537109375\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.00704464758746326, Gen Loss: 16.24728012084961\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.00307976093608886, Gen Loss: 16.436464309692383\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.006231653620488942, Gen Loss: 16.445106506347656\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.002687556901946664, Gen Loss: 16.575973510742188\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.013985745754325762, Gen Loss: 16.68251609802246\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0023851515143178403, Gen Loss: 16.88151741027832\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0023066194844432175, Gen Loss: 17.019025802612305\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0020332662970758975, Gen Loss: 17.086490631103516\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.003375999629497528, Gen Loss: 17.142044067382812\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0038855316815897822, Gen Loss: 17.252283096313477\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.0012854780652560294, Gen Loss: 17.163972854614258\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.003952447324991226, Gen Loss: 17.27083396911621\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.002567846531746909, Gen Loss: 17.179771423339844\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.004961872065905482, Gen Loss: 17.3659610748291\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.002407472115010023, Gen Loss: 17.60944366455078\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.002550883567892015, Gen Loss: 17.554502487182617\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.0016722973086871207, Gen Loss: 17.645063400268555\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.003611923864809796, Gen Loss: 17.53445053100586\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.0020344945369288325, Gen Loss: 17.629718780517578\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.006402998464182019, Gen Loss: 17.568206787109375\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.004461723379790783, Gen Loss: 17.516233444213867\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.0071429230738431215, Gen Loss: 17.374757766723633\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0034778946719598025, Gen Loss: 17.362354278564453\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.003590073305531405, Gen Loss: 17.488452911376953\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.001134767968324013, Gen Loss: 17.636058807373047\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.0008577032567700371, Gen Loss: 17.59256362915039\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.006987433531321585, Gen Loss: 17.748775482177734\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.0023811065475456417, Gen Loss: 18.005674362182617\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.009452097467146814, Gen Loss: 17.997610092163086\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0019343773601576686, Gen Loss: 17.852853775024414\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0012418127444107085, Gen Loss: 17.95142936706543\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0032039038196671754, Gen Loss: 17.963890075683594\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.0025507130194455385, Gen Loss: 18.021583557128906\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.0017944240244105458, Gen Loss: 17.999082565307617\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.002284371410496533, Gen Loss: 18.07794952392578\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.0024097809800878167, Gen Loss: 18.06407928466797\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0040186934638768435, Gen Loss: 18.210037231445312\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.0030692751170136034, Gen Loss: 18.276103973388672\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.0022272964706644416, Gen Loss: 18.299148559570312\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.004142015299294144, Gen Loss: 18.41987419128418\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.014831817767117172, Gen Loss: 18.535720825195312\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.006389306043274701, Gen Loss: 18.92853546142578\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0027001784765161574, Gen Loss: 19.255998611450195\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.0039022219134494662, Gen Loss: 19.39155387878418\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.004993617360014468, Gen Loss: 19.38456916809082\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.005300687102135271, Gen Loss: 19.183626174926758\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.008025810471735895, Gen Loss: 19.06549072265625\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.004928763723000884, Gen Loss: 18.81943702697754\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.0033897144021466374, Gen Loss: 18.796655654907227\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.004319213796406984, Gen Loss: 18.75115394592285\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0018589470419101417, Gen Loss: 18.656187057495117\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0018444598390487954, Gen Loss: 18.75828742980957\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.0015041088045109063, Gen Loss: 18.8278865814209\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.002428705047350377, Gen Loss: 19.00220489501953\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.00484267994761467, Gen Loss: 18.97278594970703\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.011856977915158495, Gen Loss: 19.257911682128906\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.00135612694430165, Gen Loss: 19.421571731567383\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.005577705684117973, Gen Loss: 19.616722106933594\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.006107924738898873, Gen Loss: 19.672954559326172\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.010743796359747648, Gen Loss: 19.663795471191406\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.004735818947665393, Gen Loss: 19.72414207458496\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0041470821015536785, Gen Loss: 19.775468826293945\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0028511349810287356, Gen Loss: 19.787784576416016\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.005147983320057392, Gen Loss: 19.946725845336914\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.006718455231748521, Gen Loss: 19.810392379760742\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.00600387598387897, Gen Loss: 20.08473777770996\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.003288831328973174, Gen Loss: 19.857412338256836\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:2, Disc Loss: 0.0035684958565980196, Gen Loss: 19.9726619720459\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.0034968455438502133, Gen Loss: 20.03326988220215\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.004349225957412273, Gen Loss: 20.089448928833008\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:2, Disc Loss: 0.003193029981048312, Gen Loss: 20.42155647277832\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.00617395353037864, Gen Loss: 20.6082706451416\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:3, Disc Loss: 0.0036035277880728245, Gen Loss: 20.890520095825195\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.004458826850168407, Gen Loss: 21.16394805908203\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.006161737954244018, Gen Loss: 21.217370986938477\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:3, Disc Loss: 0.00865544332191348, Gen Loss: 21.280799865722656\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.006868328433483839, Gen Loss: 21.441198348999023\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:3, Disc Loss: 0.004715853719972074, Gen Loss: 21.732267379760742\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.007383392192423344, Gen Loss: 21.7511043548584\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.0058685471303761005, Gen Loss: 21.684505462646484\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.004032440134324133, Gen Loss: 21.991121292114258\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:3, Disc Loss: 0.008387381676584482, Gen Loss: 22.0161075592041\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:3, Disc Loss: 0.03142828168347478, Gen Loss: 21.535673141479492\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.007361211901297793, Gen Loss: 21.773151397705078\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.005867082392796874, Gen Loss: 22.039567947387695\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.004566039249766618, Gen Loss: 22.136064529418945\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.010007992386817932, Gen Loss: 22.339527130126953\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.005544543033465743, Gen Loss: 22.415321350097656\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.018207198940217495, Gen Loss: 22.214269638061523\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.012966017238795757, Gen Loss: 22.01106834411621\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.008622128108981997, Gen Loss: 22.298847198486328\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.007537692552432418, Gen Loss: 22.486045837402344\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.00583630776964128, Gen Loss: 22.84473419189453\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:3, Disc Loss: 0.012489390792325139, Gen Loss: 22.78345489501953\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.024060208350419998, Gen Loss: 22.546274185180664\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.016794092021882534, Gen Loss: 22.51219367980957\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:3, Disc Loss: 0.014662117813713849, Gen Loss: 22.73969078063965\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:3, Disc Loss: 0.009691711864434183, Gen Loss: 23.31037139892578\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:3, Disc Loss: 0.011402853298932314, Gen Loss: 23.62859535217285\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.02944016084074974, Gen Loss: 23.76032066345215\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.03611878491938114, Gen Loss: 23.9917049407959\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:3, Disc Loss: 0.05505046993494034, Gen Loss: 24.47901725769043\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.030147884041070938, Gen Loss: 24.917768478393555\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:3, Disc Loss: 0.02876782789826393, Gen Loss: 25.086679458618164\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.06147740036249161, Gen Loss: 25.71209716796875\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:3, Disc Loss: 0.05080048181116581, Gen Loss: 26.051868438720703\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.08679071441292763, Gen Loss: 26.30059051513672\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.05577630549669266, Gen Loss: 26.455869674682617\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.1374572142958641, Gen Loss: 25.413244247436523\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.09656844660639763, Gen Loss: 25.68264389038086\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.05363747896626592, Gen Loss: 25.99072265625\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:3, Disc Loss: 0.16189206205308437, Gen Loss: 23.325958251953125\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.5491058677434921, Gen Loss: 26.27028465270996\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.32393844350008294, Gen Loss: 29.248109817504883\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:3, Disc Loss: 2.1275687287561595, Gen Loss: 18.064828872680664\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 1.8324125092476606, Gen Loss: 13.845331192016602\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.4037510138005018, Gen Loss: 14.94603157043457\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:3, Disc Loss: 0.23159890063107014, Gen Loss: 16.171194076538086\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:3, Disc Loss: 0.3393920448143035, Gen Loss: 16.0803165435791\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:3, Disc Loss: 0.5589518184424378, Gen Loss: 14.254217147827148\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:3, Disc Loss: 0.5788876821752638, Gen Loss: 11.358402252197266\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.2748703733086586, Gen Loss: 8.637166023254395\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:3, Disc Loss: 0.7504905611276627, Gen Loss: 8.162424087524414\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:3, Disc Loss: 0.15443428978323936, Gen Loss: 9.64316177368164\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:3, Disc Loss: 0.3722971377428621, Gen Loss: 9.997549057006836\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.30131255474407226, Gen Loss: 9.926887512207031\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.5738876338582486, Gen Loss: 8.95246410369873\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:3, Disc Loss: 0.3350049629807472, Gen Loss: 7.822468280792236\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.3338499143719673, Gen Loss: 6.702496528625488\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.45712926983833313, Gen Loss: 6.477588176727295\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.31282752752304077, Gen Loss: 7.00708532333374\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:3, Disc Loss: 0.17578798532485962, Gen Loss: 7.5035481452941895\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.15303723700344563, Gen Loss: 7.5933990478515625\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:3, Disc Loss: 0.3236787626519799, Gen Loss: 7.360581874847412\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "on epoch:3, Disc Loss: 0.09026118367910385, Gen Loss: 7.0616230964660645\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "on epoch:3, Disc Loss: 0.25136232003569603, Gen Loss: 6.55148458480835\n",
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m gan\u001b[38;5;241m=\u001b[39mdefine_gans(g_model, d_model)\n\u001b[0;32m      5\u001b[0m dataset\u001b[38;5;241m=\u001b[39mload_real_samples()\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgan\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(g_model, d_model, define_gan, dataset, latent_dim, n_epoch, n_batch)\u001b[0m\n\u001b[0;32m      6\u001b[0m x_real,y_real\u001b[38;5;241m=\u001b[39mgenerate_real_samples(dataset,n_samples)\n\u001b[0;32m      7\u001b[0m x_fake,y_fake\u001b[38;5;241m=\u001b[39mgenerate_fake_samples(g_model,latent_dim,n_samples)\n\u001b[1;32m----> 9\u001b[0m d_loss_real,_\u001b[38;5;241m=\u001b[39m\u001b[43md_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_real\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m d_loss_fake,_\u001b[38;5;241m=\u001b[39md_model\u001b[38;5;241m.\u001b[39mtrain_on_batch(x_fake,y_fake)\n\u001b[0;32m     12\u001b[0m d_loss\u001b[38;5;241m=\u001b[39md_loss_fake\u001b[38;5;241m+\u001b[39md_loss_real\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:2684\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   2680\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39msingle_batch_iterator(\n\u001b[0;32m   2681\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, x, y, sample_weight, class_weight\n\u001b[0;32m   2682\u001b[0m     )\n\u001b[0;32m   2683\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[1;32m-> 2684\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2686\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   2687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "latent_dim=100\n",
    "d_model=define_discriminator()\n",
    "g_model=define_generator(latent_dim)\n",
    "gan=define_gans(g_model, d_model)\n",
    "dataset=load_real_samples()\n",
    "train(g_model,d_model,gan,dataset,latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077db9b2-ec87-4d76-8c93-f0982ee3032a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
